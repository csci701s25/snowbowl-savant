{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8c2057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import binary_dilation\n",
    "from skimage.feature import structure_tensor, structure_tensor_eigenvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1ad3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches_from_edges(image_path, gt_path, r=3):\n",
    "    \"\"\"\n",
    "    Original: Canny→patches + binary labels from dilated red mask.\n",
    "    \"\"\"\n",
    "    image_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image      = cv2.imread(image_path)\n",
    "    gt_image   = cv2.imread(gt_path)\n",
    "\n",
    "    # assume red mask on GT marks ridge\n",
    "    red_mask = (gt_image[:,:,2] > 200) & (gt_image[:,:,1]<50) & (gt_image[:,:,0]<50)\n",
    "    dilated_red_mask = binary_dilation(red_mask, np.ones((3,3)))\n",
    "\n",
    "    edges = cv2.Canny(image_gray, 50, 200)\n",
    "\n",
    "    h, w = image_gray.shape\n",
    "    patches, labels = [], []\n",
    "    for y in range(r, h-r):\n",
    "        for x in range(r, w-r):\n",
    "            if edges[y,x]==0: \n",
    "                continue\n",
    "            lab = int(dilated_red_mask[y,x])\n",
    "            p = image[y-r:y+r+1, x-r:x+r+1]\n",
    "            if p.shape != (2*r+1,2*r+1,3): \n",
    "                continue\n",
    "            patches.append(p)\n",
    "            labels.append(lab)\n",
    "    return np.array(patches), np.array(labels)\n",
    "\n",
    "def load_full_dataset(image_dir, gt_dir):\n",
    "    all_patches = []\n",
    "    all_labels = []\n",
    "    for i in tqdm(range(1, 81)):\n",
    "        img_name = f\"R_GImag{i:04d}.bmp\"\n",
    "        gt_name = f\"GT_GoogleImage{i:03d}_Edge.bmp\"\n",
    "        image_path = os.path.join(image_dir, img_name)\n",
    "        gt_path = os.path.join(gt_dir, gt_name)\n",
    "        if os.path.exists(image_path) and os.path.exists(gt_path):\n",
    "            patches, labels = extract_patches_from_edges(image_path, gt_path)\n",
    "            all_patches.append(patches)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    all_patches = np.concatenate(all_patches, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Balance dataset\n",
    "    pos_indices = np.where(all_labels == 1)[0]\n",
    "    neg_indices = np.where(all_labels == 0)[0]\n",
    "    n_samples = min(len(pos_indices), len(neg_indices))\n",
    "\n",
    "    selected_pos = np.random.choice(pos_indices, n_samples, replace=False)\n",
    "    selected_neg = np.random.choice(neg_indices, n_samples, replace=False)\n",
    "\n",
    "    selected_indices = np.concatenate([selected_pos, selected_neg])\n",
    "    np.random.shuffle(selected_indices)\n",
    "\n",
    "    balanced_patches = all_patches[selected_indices]\n",
    "    balanced_labels = all_labels[selected_indices]\n",
    "\n",
    "    return balanced_patches, balanced_labels\n",
    "\n",
    "def show_example_patches(patches, labels, label_filter=None, num=10):\n",
    "    idxs = np.where(labels==label_filter)[0] if label_filter is not None else np.arange(len(patches))\n",
    "    plt.figure(figsize=(10,2))\n",
    "    for i,idx in enumerate(idxs[:num]):\n",
    "        plt.subplot(1,num,i+1)\n",
    "        plt.imshow(patches[idx])\n",
    "        plt.title(labels[idx])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3820aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — Structure‑Tensor feature maps\n",
    "\n",
    "def compute_structure_tensor_maps(gray, sigma=1.0):\n",
    "    Jxx, Jxy, Jyy = structure_tensor(gray, sigma=sigma)\n",
    "    ST = np.array([Jxx, Jxy, Jyy])\n",
    "    λ1, λ2       = structure_tensor_eigenvalues(ST)\n",
    "    strength    = np.sqrt(λ1)\n",
    "    coherence   = (λ1 - λ2) / (λ1 + λ2 + 1e-12)\n",
    "    orientation = 0.5 * np.arctan2(2*Jxy, Jxx - Jyy)\n",
    "    return strength, coherence, orientation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90586fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches_with_ST(image_path, gt_path, r=3, bucket=False, bins=None):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      patches:   (N, (2r+1)^2*3 + (bucket? one-hot:3) ) float32\n",
    "      labels:    (N,) {0,1}\n",
    "    \"\"\"\n",
    "    image_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)/255.0\n",
    "    image      = cv2.imread(image_path)\n",
    "    gt_image   = cv2.imread(gt_path)\n",
    "    # same red mask logic\n",
    "    red_mask = (gt_image[:,:,2]>200)&(gt_image[:,:,1]<50)&(gt_image[:,:,0]<50)\n",
    "    red_mask = binary_dilation(red_mask, np.ones((3,3)))\n",
    "    edges = cv2.Canny((image_gray*255).astype(np.uint8), 50,200)>0\n",
    "\n",
    "    S, C, O = compute_structure_tensor_maps(image_gray)\n",
    "    h,w = image_gray.shape\n",
    "\n",
    "    feats, labs = [], []\n",
    "    for y in range(r, h-r):\n",
    "      for x in range(r, w-r):\n",
    "        if not edges[y,x]: continue\n",
    "        lab = int(red_mask[y,x])\n",
    "        patch = image[y-r:y+r+1, x-r:x+r+1].astype(np.float32)/255.0\n",
    "        flat  = patch.reshape(-1)  # ( (2r+1)^2 * 3, )\n",
    "        s,c,o = S[y,x], C[y,x], O[y,x]\n",
    "        if bucket:\n",
    "          sb = np.digitize(s, bins['strength'])-1\n",
    "          cb = np.digitize(c, bins['coherence'])-1\n",
    "          ob = np.digitize(o, bins['orientation'])-1\n",
    "          s_feat = np.eye(len(bins['strength'])-1)[sb]\n",
    "          c_feat = np.eye(len(bins['coherence'])-1)[cb]\n",
    "          o_feat = np.eye(len(bins['orientation'])-1)[ob]\n",
    "          f = np.concatenate([flat, s_feat, c_feat, o_feat])\n",
    "        else:\n",
    "          f = np.concatenate([flat, [s,c,o]])\n",
    "        feats.append(f); labs.append(lab)\n",
    "\n",
    "    return np.stack(feats).astype(np.float32), np.array(labs).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff05d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(X, y, bs=64):\n",
    "    ds = TensorDataset(torch.from_numpy(X), torch.from_numpy(y).unsqueeze(1))\n",
    "    n = len(ds); t = int(0.8*n)\n",
    "    tr, te = random_split(ds, [t, n-t])\n",
    "    return DataLoader(tr, batch_size=bs, shuffle=True), DataLoader(te, batch_size=bs, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74446224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeClassifier(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return torch.sigmoid(self.fc3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88439330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: (7138070, 147) (7138070,)\n",
      "ST-Continuous: (7138070, 150) (7138070,)\n",
      "ST-Bucketed: (7138070, 172) (7138070,)\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"web_dataset/images\"\n",
    "gt_dir    = \"web_dataset/ground_truth\"\n",
    "patch_size=7  # 2*r+1\n",
    "r = patch_size//2\n",
    "\n",
    "# 1) ORIGINAL\n",
    "orig_patches_list, orig_labels_list = [], []\n",
    "for i in range(1, 81):\n",
    "    img_name = f\"R_GImag{i:04d}.bmp\"\n",
    "    gt_name  = f\"GT_GoogleImage{i:03d}_Edge.bmp\"\n",
    "    ip = os.path.join(image_dir, img_name)\n",
    "    gp = os.path.join(gt_dir,   gt_name)\n",
    "    if os.path.exists(ip) and os.path.exists(gp):\n",
    "        p, l = extract_patches_from_edges(ip, gp, r=r)\n",
    "        orig_patches_list.append(p)\n",
    "        orig_labels_list.append(l)\n",
    "\n",
    "orig_patches = np.concatenate(orig_patches_list, axis=0)\n",
    "orig_labels  = np.concatenate(orig_labels_list,  axis=0)\n",
    "X_orig = orig_patches.reshape(len(orig_patches), -1).astype(np.float32)/255.0\n",
    "y_orig = orig_labels.astype(np.float32)\n",
    "\n",
    "# 2) ST-CONTINUOUS\n",
    "st_feats_list, st_labels_list = [], []\n",
    "for i in range(1, 81):\n",
    "    img_name = f\"R_GImag{i:04d}.bmp\"\n",
    "    gt_name  = f\"GT_GoogleImage{i:03d}_Edge.bmp\"\n",
    "    ip = os.path.join(image_dir, img_name)\n",
    "    gp = os.path.join(gt_dir,   gt_name)\n",
    "    if os.path.exists(ip) and os.path.exists(gp):\n",
    "        f, l = extract_patches_with_ST(ip, gp, r=r, bucket=False)\n",
    "        st_feats_list.append(f)\n",
    "        st_labels_list.append(l)\n",
    "\n",
    "X_st = np.concatenate(st_feats_list, axis=0)\n",
    "y_st = np.concatenate(st_labels_list, axis=0)\n",
    "\n",
    "# Define bins based on ST continuous features\n",
    "bins = {\n",
    "  'strength':    np.linspace(0, np.max(X_st[:,-3]), 6+1),\n",
    "  'coherence':   np.linspace(0, 1.0,               3+1),\n",
    "  'orientation': np.linspace(-np.pi/2, np.pi/2,   16+1),\n",
    "}\n",
    "\n",
    "# 3) ST-BUCKETED\n",
    "bkt_feats_list, bkt_labels_list = [], []\n",
    "for i in range(1, 81):\n",
    "    img_name = f\"R_GImag{i:04d}.bmp\"\n",
    "    gt_name  = f\"GT_GoogleImage{i:03d}_Edge.bmp\"\n",
    "    ip = os.path.join(image_dir, img_name)\n",
    "    gp = os.path.join(gt_dir,   gt_name)\n",
    "    if os.path.exists(ip) and os.path.exists(gp):\n",
    "        f, l = extract_patches_with_ST(ip, gp, r=r, bucket=True, bins=bins)\n",
    "        bkt_feats_list.append(f)\n",
    "        bkt_labels_list.append(l)\n",
    "\n",
    "X_bkt = np.concatenate(bkt_feats_list, axis=0)\n",
    "y_bkt = np.concatenate(bkt_labels_list, axis=0)\n",
    "\n",
    "# Create DataLoaders\n",
    "loader_orig = make_loader(X_orig, y_orig)\n",
    "loader_st   = make_loader(X_st,   y_st)\n",
    "loader_bkt  = make_loader(X_bkt,  y_bkt)\n",
    "\n",
    "print(\"Original:\", X_orig.shape, y_orig.shape)\n",
    "print(\"ST-Continuous:\", X_st.shape, y_st.shape)\n",
    "print(\"ST-Bucketed:\", X_bkt.shape, y_bkt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "702ee4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6 True\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4151318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ORIGINAL\n",
      "Training on cuda.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep0: 100%|██████████| 89226/89226 [03:58<00:00, 373.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 0.0158, Acc: 0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep1: 100%|██████████| 89226/89226 [05:22<00:00, 276.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 0.0146, Acc: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep2:  31%|███▏      | 27921/89226 [01:50<04:00, 255.29it/s]"
     ]
    }
   ],
   "source": [
    "def train_eval(loader, in_dim, lr=3e-3, epochs=5):\n",
    "    train_loader, test_loader = loader\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on {device}.\\n\")\n",
    "    model = RidgeClassifier(in_dim).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for xb,yb in tqdm(train_loader, desc=f\"Ep{ep}\"):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = loss_fn(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        # eval\n",
    "        model.eval()\n",
    "        tot, cnt, acc = 0.,0,0\n",
    "        with torch.no_grad():\n",
    "            for xb,yb in test_loader:\n",
    "                xb,yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                tot += loss_fn(out,yb).item()*len(xb)\n",
    "                cnt += len(xb)\n",
    "                pred = (out>0.5).float()\n",
    "                acc += (pred==yb).sum().item()\n",
    "        print(f\"  Val Loss: {tot/cnt:.4f}, Acc: {acc/cnt:.3f}\")\n",
    "    return model\n",
    "\n",
    "# run all three\n",
    "print(\">>> ORIGINAL\")\n",
    "m0 = train_eval(loader_orig, X_orig.shape[1])\n",
    "\n",
    "print(\">>> ST CONTINUOUS\")\n",
    "m1 = train_eval(loader_st,   X_st.shape[1])\n",
    "\n",
    "print(\">>> ST BUCKETED\")\n",
    "m2 = train_eval(loader_bkt,  X_bkt.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3498669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
